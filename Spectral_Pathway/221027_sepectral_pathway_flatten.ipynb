{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDWt74XAgpLK",
        "outputId": "383e98fe-23c9-4455-a10a-7cd0373ea662"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mne in /usr/local/lib/python3.7/dist-packages (1.2.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from mne) (1.7.3)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mne) (3.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from mne) (4.64.1)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.7/dist-packages (from mne) (1.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mne) (21.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from mne) (2.11.3)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from mne) (1.21.6)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.5->mne) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.5->mne) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->mne) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (1.24.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->mne) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mne) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mne) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mne) (1.4.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mne) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->mne) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install mne"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "l4YUYhC7E4Ck"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "import pickle\n",
        "import mne\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "class Sleepedf_dataset(Dataset):\n",
        "    def __init__(self, files, seq_len, SSL = bool):\n",
        "        self.files = files\n",
        "        self.sequence_length = seq_len\n",
        "        self.SSL = SSL\n",
        "        # sample을 split해줬을 때 몇개로 split되는지 누적해서 저장, i번째 data를 찾을 때 data_adress 각 값이 기준이 됨\n",
        "        data_adress = [0]\n",
        "        ad = 0\n",
        "        max_value = 0.\n",
        "        min_value = 0.\n",
        "\n",
        "        for i in range(len(self.files)):\n",
        "            sample = np.load(files[i])['x']\n",
        "            c,t = sample.shape\n",
        "            t = int(t/self.sequence_length) \n",
        "            ad += t\n",
        "            data_adress.append(ad)\n",
        "            temp_max = sample.max()\n",
        "            temp_min = sample.min()\n",
        "            max_value = np.max([max_value, temp_max])\n",
        "            min_value = np.min([min_value, temp_min])\n",
        "        \n",
        "        self.data_adress = data_adress\n",
        "        self.max_value = max_value\n",
        "        self.min_value = min_value\n",
        "\n",
        "    def preprocessing(self, data):\n",
        "        data_max = np.max(data,axis = 2, keepdims=True) # max value of each channels\n",
        "        data_min = np.min(data,axis = 2, keepdims=True) # shape = b,c\n",
        "        b,c,t = data.shape\n",
        "        \n",
        "        return data/data_max*np.ones((b,c,t)) - (data_max - data_min)*np.ones((b,c,t))/(self.max_value - self.min_value)\n",
        "\n",
        "\n",
        "    def split_data(self, data):\n",
        "        L = self.sequence_length\n",
        "        channels, length = data.shape\n",
        "        a = L*int(length/L)\n",
        "        \n",
        "        if length == a:\n",
        "            data = np.reshape(data,(int(length/L),channels,L))\n",
        "        \n",
        "        else:\n",
        "            data = data[:,:a]\n",
        "            data = np.reshape(data,(int(a/L),channels,L))\n",
        "        return data\n",
        "\n",
        "    def one_hot_encoding(self,y):\n",
        "        if y == 'Sleep stage W':\n",
        "          y = np.array([1,0,0,0,0])\n",
        "        elif y == 'Sleep stage 1':\n",
        "          y = np.array([0,1,0,0,0])\n",
        "        elif y == 'Sleep stage 2':\n",
        "          y = np.array([0,0,1,0,0])   \n",
        "        elif y == 'Sleep stage 3':\n",
        "          y = np.array([0,0,0,1,0])\n",
        "        elif y == 'Sleep stage R':\n",
        "          y = np.array([0,0,0,0,1])      \n",
        "        return y  \n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        for i in range(len(self.data_adress)):\n",
        "            if index < self.data_adress[i]:\n",
        "                break\n",
        "          \n",
        "        sample = np.load(self.files[i-1])  \n",
        "        y = self.one_hot_encoding(sample['y'])\n",
        "        sample = self.split_data(sample['x'])\n",
        "        sample = self.preprocessing(sample)\n",
        "\n",
        "        if self.SSL:\n",
        "          return sample[index - self.data_adress[i-1],:,:]\n",
        "        else:\n",
        "          return { 'x' : torch.tensor(sample[index - self.data_adress[i-1],:,:]), \n",
        "                   'y' : torch.tensor(y)\n",
        "                   }\n",
        "\n",
        "          \n",
        "          \n",
        "    def __len__(self):\n",
        "        return self.data_adress[-1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "x59y8HGhPIQB"
      },
      "outputs": [],
      "source": [
        "class MASS_dataset(Dataset):\n",
        "    def __init__(self, files, seq_len, SSL = bool):\n",
        "        self.files = files\n",
        "        self.sequence_length = seq_len\n",
        "        self.SSL = SSL\n",
        "        # self.freq = 1.28 # 256Hz / 1.28 = 200Hz\n",
        "        # sample을 split해줬을 때 몇개로 split되는지 누적해서 저장, i번째 data를 찾을 때 data_adress 각 값이 기준이 됨\n",
        "        data_adress = [0]\n",
        "        ad = 0\n",
        "        max_value = 0.\n",
        "        min_value = 0.\n",
        "\n",
        "        for i in range(len(self.files)):\n",
        "            sample = np.load(files[i])['x']\n",
        "            c,t = sample.shape\n",
        "            t = int(t/self.sequence_length) \n",
        "            ad += t\n",
        "            data_adress.append(ad)\n",
        "            temp_max = sample.max()\n",
        "            temp_min = sample.min()\n",
        "            max_value = np.max([max_value, temp_max])\n",
        "            min_value = np.min([min_value, temp_min])\n",
        "      \n",
        "        self.data_adress = data_adress\n",
        "        self.max_value = max_value\n",
        "        self.min_value = min_value\n",
        "\n",
        "    def preprocessing(self, data):\n",
        "        data_max = np.max(data,axis = 2, keepdims=True) # max value of each channels\n",
        "        data_min = np.min(data,axis = 2, keepdims=True) # shape = b,c\n",
        "        b,c,t = data.shape\n",
        "        \n",
        "        return data/data_max*np.ones((b,c,t)) - (data_max - data_min)*np.ones((b,c,t))/(self.max_value - self.min_value)\n",
        "\n",
        "\n",
        "    def split_data(self, data):\n",
        "        L = self.sequence_length\n",
        "        channels, length = data.shape\n",
        "        a = L*int(length/L)\n",
        "        \n",
        "        if length == a:\n",
        "            data = np.reshape(data,(int(length/L),channels,L))\n",
        "        \n",
        "        else:\n",
        "            data = data[:,:a]\n",
        "            data = np.reshape(data,(int(a/L),channels,L))\n",
        "        return data\n",
        "\n",
        "    def one_hot_encoding(self,y):\n",
        "        if y == 'Sleep stage W':\n",
        "          y = np.array([1,0,0,0,0])\n",
        "        elif y == 'Sleep stage 1':\n",
        "          y = np.array([0,1,0,0,0])\n",
        "        elif y == 'Sleep stage 2':\n",
        "          y = np.array([0,0,1,0,0])   \n",
        "        elif y == 'Sleep stage 3':\n",
        "          y = np.array([0,0,0,1,0])\n",
        "        elif y == 'Sleep stage R':\n",
        "          y = np.array([0,0,0,0,1])      \n",
        "        return y  \n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        for i in range(len(self.data_adress)):\n",
        "            if index < self.data_adress[i]:\n",
        "                break\n",
        "          \n",
        "        sample = np.load(self.files[i-1])  \n",
        "        y = self.one_hot_encoding(sample['y'])\n",
        "        sample = self.split_data(sample['x'])\n",
        "        sample = self.preprocessing(sample)\n",
        "\n",
        "        if self.SSL:\n",
        "          return sample[index - self.data_adress[i-1],:,:]\n",
        "        else:\n",
        "          return { 'x' : torch.tensor(sample[index - self.data_adress[i-1],:,:]), \n",
        "                   'y' : torch.tensor(y)\n",
        "                   }\n",
        "\n",
        "          \n",
        "    def __len__(self):\n",
        "        return self.data_adress[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dK-L4S1ZPOy8"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class concat_dataset():\n",
        "    def __init__(self, data_dic,seq_len):\n",
        "        self.data_dic = data_dic #data_dic : {'dataset1_name : [dataset1_adress],,,datasetN_name : [datasetN_adress]}\n",
        "        self.seq_len = seq_len\n",
        "    \n",
        "    def tr_val_te_split(self,data_list):\n",
        "        train, test = train_test_split(data_list, test_size=0.2)#, shuffle=True, random_state=34), #stratify=target\n",
        "        train, val = train_test_split(train, test_size= 0.25)#, shuffle=True, random_state=34)\n",
        "        del data_list\n",
        "        print('split done')\n",
        "        return train, val, test    \n",
        "    \n",
        "    def call(self):\n",
        "        # train_dataset = [] # extend로 빈 어레의 받으면 메모리가 터지는 문제 발생했음.\n",
        "        # val_dataset = []\n",
        "        # test_dataset = []\n",
        "    \n",
        "        for name, data_list in self.data_dic.items():\n",
        "            print(name)\n",
        "            tr, val, te = self.tr_val_te_split(data_list)\n",
        "            \n",
        "            if name =='Sleep_edf':\n",
        "                sleepedf_train_data = Sleepedf_dataset(tr,self.seq_len,SSL = True)\n",
        "                print('sleep train done')\n",
        "                sleepedf_val_data = Sleepedf_dataset(val,self.seq_len, SSL = True)\n",
        "                print('sleep val done')\n",
        "                sleepedf_test_data = Sleepedf_dataset(te,self.seq_len, SSL = True)\n",
        "                print('sleep test done')\n",
        "            \n",
        "            elif name == 'MASS':\n",
        "                MASS_train_data = Sleepedf_dataset(tr,self.seq_len, SSL = True)\n",
        "                print('MASS train done')\n",
        "                MASS_val_data = Sleepedf_dataset(val,self.seq_len, SSL = True)\n",
        "                print('MASS val done')\n",
        "                MASS_test_data = Sleepedf_dataset(te,self.seq_len, SSL = True)\n",
        "                print('MASS test done')\n",
        "        \n",
        "            # train_dataset.extend(train_data)\n",
        "            # val_dataset.extend(val_data)\n",
        "            # test_dataset.extend(test_data)\n",
        "            # print(train_data)\n",
        "\n",
        "        # del train_data,val_data, test_data\n",
        "    \n",
        "        train_dataset = torch.utils.data.ConcatDataset([sleepedf_train_data,MASS_train_data])\n",
        "        val_dataset = torch.utils.data.ConcatDataset([sleepedf_test_data,MASS_val_data])\n",
        "        test_dataset = torch.utils.data.ConcatDataset([sleepedf_val_data,MASS_test_data])\n",
        "    \n",
        "        return train_dataset, val_dataset, test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pk5UWrymWlfa",
        "outputId": "d55796b4-525e-44d9-c0bb-0417b3914d9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "153\n",
            "2650\n",
            "2830\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5480"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import glob\n",
        "SC_list = glob.glob('/content/drive/MyDrive/sleep_edfx/Preprocessed_EEG/SC/**')\n",
        "print(len(SC_list))\n",
        "sleepedf_list = []\n",
        "for i in range(2):\n",
        "  length = len(sleepedf_list)\n",
        "  sleepedf_list.extend(glob.glob(SC_list[i]+'/**'))\n",
        "  print(len(sleepedf_list) - length)\n",
        "len(sleepedf_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obBikyK6Wlhg",
        "outputId": "5de047b4-72c9-4fe9-a6cf-88ec8e0f3f8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53\n",
            "1004\n",
            "1071\n",
            "937\n",
            "1041\n",
            "1079\n",
            "991\n",
            "877\n",
            "7000\n"
          ]
        }
      ],
      "source": [
        "SS1_list = glob.glob('/content/drive/MyDrive/EEG_data/MASS/SS1/Preprocessed_EEGedf/**')\n",
        "print(len(SS1_list))\n",
        "MASS_list = []\n",
        "for i in range(7,14):\n",
        "    length = len(MASS_list)\n",
        "    MASS_list.extend(glob.glob(SS1_list[i]+'/**'))\n",
        "    print(len(MASS_list) - length)\n",
        "print(len(MASS_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "eY3pJkIbWoFC"
      },
      "outputs": [],
      "source": [
        "data_dic = {'MASS' : MASS_list[:1000], 'Sleep_edf': sleepedf_list[:1000]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pb6mPckKWoHR",
        "outputId": "221aa18a-b171-41a0-e347-6be35cfc44aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MASS\n",
            "split done\n",
            "MASS train done\n",
            "MASS val done\n",
            "MASS test done\n",
            "Sleep_edf\n",
            "split done\n",
            "sleep train done\n",
            "sleep val done\n",
            "sleep test done\n"
          ]
        }
      ],
      "source": [
        "train_dataset, val_dataset, test_dataset = concat_dataset(data_dic, seq_len = 2000).call()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CcmiiI43YFCV"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "trainLoader = DataLoader(train_dataset, batch_size = 10 , shuffle= False)\n",
        "valLoader = DataLoader(val_dataset, batch_size = 10 , shuffle= False)\n",
        "testLoader = DataLoader(test_dataset, batch_size = 10 , shuffle= False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YWymlqfWs4T",
        "outputId": "e26f5616-5aa1-4740-c1c0-b515e32adf3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch_idx: 0   torch.Size([10, 2, 2000])\n",
            "time: 0.10629081726074219\n",
            "batch_idx: 1   torch.Size([10, 2, 2000])\n",
            "time: 0.12753725051879883\n",
            "batch_idx: 2   torch.Size([10, 2, 2000])\n",
            "time: 0.1474754810333252\n",
            "batch_idx: 3   torch.Size([10, 2, 2000])\n",
            "time: 0.16811466217041016\n",
            "batch_idx: 4   torch.Size([10, 2, 2000])\n",
            "time: 0.19106101989746094\n",
            "batch_idx: 5   torch.Size([10, 2, 2000])\n",
            "time: 0.21094131469726562\n",
            "batch_idx: 6   torch.Size([10, 2, 2000])\n",
            "time: 0.23074817657470703\n",
            "batch_idx: 7   torch.Size([10, 2, 2000])\n",
            "time: 0.2509746551513672\n",
            "batch_idx: 8   torch.Size([10, 2, 2000])\n",
            "time: 0.27080345153808594\n",
            "batch_idx: 9   torch.Size([10, 2, 2000])\n",
            "time: 0.2900559902191162\n",
            "batch_idx: 10   torch.Size([10, 2, 2000])\n",
            "time: 0.31314802169799805\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_T = time.time()\n",
        "for batch_idx, batch in enumerate(valLoader):\n",
        "  print('batch_idx:',batch_idx,' ',batch.shape)\n",
        "  end_T = time.time()\n",
        "  print('time:', end_T - start_T)\n",
        "  if batch_idx >= 10:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "834tX7V_uCyj",
        "outputId": "266e9d3b-1be2-4256-e884-53be7024396b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting separableconv-torch\n",
            "  Downloading separableconv_torch-0.1.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from separableconv-torch) (1.21.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from separableconv-torch) (1.12.1+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from separableconv-torch) (0.13.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->separableconv-torch) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->separableconv-torch) (2.23.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->separableconv-torch) (7.1.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->separableconv-torch) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->separableconv-torch) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->separableconv-torch) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->separableconv-torch) (2.10)\n",
            "Installing collected packages: separableconv-torch\n",
            "Successfully installed separableconv-torch-0.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install separableconv-torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "AISU52mNuvT0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from mne.filter import filter_data, notch_filter\n",
        "import matplotlib.pyplot as plt\n",
        "# import hypertools as hyp\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def accuracy_check(pred, label):\n",
        "    prediction = np.argmax(pred, axis=1)\n",
        "    lb = np.argmax(label, axis=1)\n",
        "\n",
        "    compare = np.equal(lb, prediction)\n",
        "    accuracy = np.sum(compare.tolist()) / len(compare.tolist())\n",
        "\n",
        "    f1acc = f1_score(lb, prediction, average='micro')\n",
        "\n",
        "    return accuracy, f1acc\n",
        "\n",
        "def dotprod_sample(sample):\n",
        "    length = sample.shape[0]\n",
        "    sam = nn.functional.normalize(sample.reshape([length,-1]), dim=1)\n",
        "    result = torch.matmul(sam, sam.T)\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "TRAIN = 0\n",
        "VALIDATION = 1\n",
        "TEST = 2\n",
        "\n",
        "class StoppedBandPredTaskLoss(torch.nn.modules.loss._Loss):\n",
        "    def __init__(self, bands, labels, device):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.BAND = bands\n",
        "        self.LABEL = labels\n",
        "\n",
        "    def forward(self, batch, encoder, sfreq, train):\n",
        "        batch_aug = []\n",
        "        batch_label = []\n",
        "        b,c,t = batch.shape\n",
        "        batch = np.reshape(batch,(b*c,t))        #Band has freqeuncy range, filter_data plays the role of Band Stop filter\n",
        "        \n",
        "        #each Labels are composed of one-hot vectors and are copied ( Bands size * Batch size )\n",
        "        for idx,band in enumerate(self.BAND):\n",
        "            lfreq, rfreq = band\n",
        "            data = filter_data(batch.numpy().astype(np.float64), sfreq=200, l_freq=rfreq, h_freq=lfreq, verbose=False)\n",
        "            batch_aug.extend(data)\n",
        "            batch_label.extend(data.shape[0] * [self.LABEL[idx]])\n",
        "\n",
        "        #[batch, augmentation, channel, time length] -> [batch*augmentation, channel, time length]\n",
        "        # b,a,l = np.array(batch_aug).shape\n",
        "        batch_aug = np.array(batch_aug)\n",
        " \n",
        "        batch_label = np.array(batch_label)\n",
        "        c,t = batch_aug.shape\n",
        "        batch_aug = np.reshape(batch_aug,(c,1,t))\n",
        "        batch_label = torch.Tensor(batch_label).to(device)\n",
        "  \n",
        "        #Self-supervised Learning Loss is CrossEntropy\n",
        "        CrossEL = torch.nn.CrossEntropyLoss()\n",
        "        pred = encoder.forward(torch.Tensor(batch_aug).to(device))\n",
        "        loss = CrossEL(pred, batch_label)\n",
        "        _, y =  torch.max(batch_label, 1) \n",
        "        _, predicted = torch.max(pred, 1) \n",
        "        \n",
        "    \n",
        "        if train:\n",
        "            loss.backward(retain_graph=True)\n",
        "            \n",
        "        acc = (predicted == y).sum().item()\n",
        "        acc = acc/c #acc/(batch*channels*4(augmented))\n",
        "        loss = loss\n",
        "      \n",
        "        del y\n",
        "        return loss, acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "aJVoejtCuxGB"
      },
      "outputs": [],
      "source": [
        "def weight_init_xavier_uniform(submodule):\n",
        "    # if isinstance(submodule, snn.SeparableConv1d):\n",
        "    #     torch.nn.init.xavier_uniform_(submodule.weight)\n",
        "\n",
        "    if isinstance(submodule, nn.Linear):\n",
        "        torch.nn.init.xavier_uniform_(submodule.weight)\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, fs, encode_info):\n",
        "        super(Encoder, self).__init__()\n",
        "        #spectral layer means spectral convolution\n",
        "        #self.bac_layer is consist of several SeparableConv2d, which plays the role of temporal separable convolution\n",
        "        #convolution layer are initiated by xavier_uniform initization\n",
        "        #Input are Normalized by self.bn(=torch.nn.BatchNorm2d)\n",
        "        #[batch, electrode, length] -> [batch, electrode, Feature]\n",
        "        self.fs = fs\n",
        "        self.elu = nn.ELU()\n",
        "        self.maxpool = nn.AdaptiveMaxPool1d(1)\n",
        "        self.bn = nn.BatchNorm1d(1)\n",
        "        self.activation = nn.LeakyReLU()\n",
        "\n",
        "        self.spectral_layer = nn.Conv1d(1, 10, int(self.fs/2), padding=\"same\")\n",
        "\n",
        "        # self.bac_layer = nn.Sequential()\n",
        "        # for i, arg in enumerate(encode_info):\n",
        "        #     input_dim, output_dim, kernel_size = arg\n",
        "        #     self.bac_layer.add_module(\"temporal_conv_\"+str(i),\n",
        "        #                           nn.Conv1d(input_dim, output_dim, kernel_size, padding = 'same'))\n",
        "        #     self.bac_layer.add_module(\"ELU\",nn.ELU()) \n",
        "        \n",
        "        self.conv1t = nn.Conv1d(10,16, 30, padding ='same')\n",
        "        self.conv2t = nn.Conv1d(16,32, 15, padding ='same')\n",
        "        self.conv3t = nn.Conv1d(32,64, 5, padding ='same')\n",
        "        \n",
        "        # torch.nn.init.xavier_uniform_(self.spectral_layer.weight)\n",
        "        #self.bac_layer.apply(weight_init_xavier_uniform)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.activation(self.spectral_layer(x))\n",
        "        x = self.activation(self.conv1t(x))\n",
        "        x = self.activation(self.conv2t(x))\n",
        "        x = self.activation(self.conv3t(x))\n",
        "\n",
        "        return x\n",
        "\n",
        "#Linear layer for SSL classification\n",
        "class Head_NN(nn.Module):\n",
        "    def __init__(self, length):\n",
        "        super(Head_NN, self).__init__()\n",
        "        self.length = length\n",
        "        \n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(64*length, 5)\n",
        "        )\n",
        "        \n",
        "        # self.layer = nn.Sequential(\n",
        "        #     nn.Dropout(0.5),\n",
        "        #     nn.Linear(64, 5)\n",
        "        # )\n",
        "        \n",
        "        self.softmax = torch.nn.Softmax()\n",
        "        # self.layer.apply(weight_init_xavier_uniform)\n",
        "        self.bn = nn.BatchNorm1d(64)\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x = torch.mean(x, axis = 2) # Global average pooling into temporal dimension\n",
        "        x = self.flatten(x)\n",
        "        x = self.layer(x)\n",
        "        x = self.softmax(x)\n",
        "        return x\n",
        "\n",
        "class StoppedBandPathway(nn.Module):\n",
        "    def __init__(self, fs, Unsupervise, encode_info, bands):\n",
        "        super(StoppedBandPathway, self).__init__()\n",
        "        self.encoder = Encoder(fs, encode_info)\n",
        "        self.pretrain = Head_NN(2000)\n",
        "        self.Unsupervise = Unsupervise\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.pretrain(x)\n",
        "        return x\n",
        "\n",
        "    def getRep(self, x):\n",
        "        x = self.encoder(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "E-HDYWxLaZiA"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import torch\n",
        "# batch size\n",
        "batch_size = 20\n",
        "learning_rate = 0.01\n",
        "epochs = 10\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "#torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "#\"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TiQ9BH615R_",
        "outputId": "3a85ca5b-730a-4f27-8ebe-2060516a7a31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "SpnINn5J2AVM"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "trainLoader = DataLoader(train_dataset, batch_size = batch_size , shuffle= False)\n",
        "valLoader = DataLoader(val_dataset, batch_size = batch_size , shuffle= False)\n",
        "testLoader = DataLoader(test_dataset, batch_size = batch_size , shuffle= False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "gPM0DbXxuz9n"
      },
      "outputs": [],
      "source": [
        "BANDS = [(0.5,4), (4,8), (8,15), (15,30), (30,49.9)]\n",
        "LABEL = [[1,0,0,0,0],[0,1,0,0,0],[0,0,1,0,0],[0,0,0,1,0],[0,0,0,0,1]]\n",
        "\n",
        "encode_info = [(10, 16, 30),(16, 32, 15),(32, 64, 5)]\n",
        "sfreq = 200\n",
        "\n",
        "\n",
        "model = StoppedBandPathway(sfreq,True,encode_info,BANDS).to(device)\n",
        "#model = MSNN.feature_extractor3(sfreq).to(device)\n",
        "\n",
        "# Custom Tripletloss\n",
        "criterion = StoppedBandPredTaskLoss(BANDS, LABEL, device=device)\n",
        "\n",
        "\n",
        "# use Adam optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "sfGyOdRAbtyv",
        "outputId": "5e9aa10e-b326-4ccf-9b51-81599134103e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:71: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch :  0   train loss :  1.7039788623650869 train acc :  0.19991666666666655     val loss :  1.7048326134681702 val acc :  0.19999999999999982\n",
            "epoch :  1   train loss :  1.7048326134681702 train acc :  0.19999999999999984     val loss :  1.7048326134681702 val acc :  0.19999999999999982\n",
            "epoch :  2   train loss :  1.7048326134681702 train acc :  0.19999999999999984     val loss :  1.7048326134681702 val acc :  0.19999999999999982\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-55435c9804ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# print(batch.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msfreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss_ep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-d51203a4971d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batch, encoder, sfreq, train)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mband\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBAND\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mlfreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrfreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mband\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msfreq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrfreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlfreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0mbatch_aug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mbatch_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLABEL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-261>\u001b[0m in \u001b[0;36mfilter_data\u001b[0;34m(data, sfreq, l_freq, h_freq, picks, filter_length, l_trans_bandwidth, h_trans_bandwidth, n_jobs, method, iir_params, copy, phase, fir_window, fir_design, pad, verbose)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mne/filter.py\u001b[0m in \u001b[0;36mfilter_data\u001b[0;34m(data, sfreq, l_freq, h_freq, picks, filter_length, l_trans_bandwidth, h_trans_bandwidth, n_jobs, method, iir_params, copy, phase, fir_window, fir_design, pad, verbose)\u001b[0m\n\u001b[1;32m    815\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'fir'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fft'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         data = _overlap_add_filter(data, filt, None, phase, picks, n_jobs,\n\u001b[0;32m--> 817\u001b[0;31m                                    copy, pad)\n\u001b[0m\u001b[1;32m    818\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_filtfilt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpicks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mne/filter.py\u001b[0m in \u001b[0;36m_overlap_add_filter\u001b[0;34m(x, h, n_fft, phase, picks, n_jobs, copy, pad)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         data_new = parallel(p_fun(x[p], len(h), n_edge, phase,\n\u001b[0;32m--> 209\u001b[0;31m                                   cuda_dict, pad, n_fft) for p in picks)\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpicks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 289\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 289\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mne/filter.py\u001b[0m in \u001b[0;36m_1d_overlap_filter\u001b[0;34m(x, n_h, n_edge, phase, cuda_dict, pad, n_fft)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mseg_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_seg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mseg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_ext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0mseg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_fft\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mprod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fft_multiply_repeated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/multiarray.py\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(arrays, axis, out, dtype, casting)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0marray_function_from_c_func_and_dispatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_multiarray_umath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \"\"\"\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "loss_tr = []\n",
        "loss_val = []\n",
        "acc_tr = []\n",
        "acc_val = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    loss_ep = 0  # add batch loss in epoch\n",
        "    acc_ep = 0\n",
        "    #concatdata.getTrain()\n",
        "    for batch_idx, batch in enumerate(trainLoader):\n",
        "        optimizer.zero_grad()\n",
        "        # print(batch.shape)\n",
        "        loss_batch, acc_batch = criterion.forward(batch, model, sfreq, train = True)\n",
        "        optimizer.step()\n",
        "        loss_ep += loss_batch.item()\n",
        "        acc_ep += acc_batch\n",
        "        # print('acc',acc_batch)\n",
        "        # print('loss:',loss_batch.item())\n",
        "    loss_tr.append((loss_ep)/len(trainLoader))\n",
        "    acc_tr.append((acc_ep)/len(trainLoader))\n",
        "\n",
        "    loss_ep_val = 0\n",
        "    acc_ep_val = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        loss_v = 0\n",
        "        acc_v = 0\n",
        "        #concatdata.getVal()\n",
        "        for batch_idx, batch in enumerate(valLoader):\n",
        "            loss_batch, acc_batch = criterion.forward(batch, model, sfreq, train = False)\n",
        "            loss_ep_val += loss_batch.item()\n",
        "            acc_ep_val += acc_batch\n",
        "    \n",
        "        loss_val.append((loss_ep_val)/len(valLoader))\n",
        "        acc_val.append((acc_ep_val)/len(valLoader))\n",
        "        print(\"epoch : \", epoch, \"  train loss : \", loss_tr[epoch], 'train acc : ', acc_tr[epoch], \"    val loss : \", loss_val[epoch], 'val acc : ', acc_val[epoch])  \n",
        "        torch.save(model,'Spectral__10s_ep' + str(epoch)+'_.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6iBV4I-bt1N"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9QLOrL3hq-f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyYjI6wY4bew"
      },
      "source": [
        "result save and plot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 3\n"
      ],
      "metadata": {
        "id": "otiESYAaRVvz"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sULgDLvm2xHe",
        "outputId": "d42e1506-a472-4117-ea4b-6fcbfea1b45c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 3)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "col = ['loss_tr','loss_val','acc_tr','acc_val']\n",
        "data = np.array([loss_tr,\n",
        "                 loss_val,\n",
        "                 acc_tr,\n",
        "                 acc_val])\n",
        "print(data.shape)\n",
        "data = np.transpose(data)\n",
        "df = pd.DataFrame(data = data, columns= col)\n",
        "df.to_excel('s_Sleepedf+MASS_10s.xlsx', index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "yqo5atQngb6K",
        "outputId": "3fc0a595-62c0-4809-df46-f5a45639afce"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# plt.figure(figsize =(15, 10))\n",
        "\n",
        "plt.plot(range(epochs), loss_tr, color='red')\n",
        "plt.plot(range(epochs), loss_val, color='blue')\n",
        "plt.title('Model loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "plt.savefig('s_Sleepedf+MASS_loss_10s',bbox_inches = 'tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "0qR7XCy2hPq6",
        "outputId": "4406951e-c8a4-40ef-e615-a6f906c117bb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# plt.figure(figsize =(15, 10))\n",
        "plt.plot(range(epochs), acc_tr, color='red')\n",
        "plt.plot(range(epochs), acc_val, color='blue')\n",
        "plt.title('Model accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "plt.savefig('s_Sleepedf+MASS_accuracy_10s',bbox_inches = 'tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaNXMjTxw00n"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "n2HeGrHBwziU"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache() # GPU 캐시 데이터 삭제"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKq8oqGJ9vrw",
        "outputId": "d390a418-86ea-4a33-ac56-3bdc621be911"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StoppedBandPathway(\n",
              "  (encoder): Encoder(\n",
              "    (elu): ELU(alpha=1.0)\n",
              "    (maxpool): AdaptiveMaxPool1d(output_size=1)\n",
              "    (bn): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (activation): LeakyReLU(negative_slope=0.01)\n",
              "    (spectral_layer): Conv1d(1, 10, kernel_size=(100,), stride=(1,), padding=same)\n",
              "    (conv1t): Conv1d(10, 16, kernel_size=(30,), stride=(1,), padding=same)\n",
              "    (conv2t): Conv1d(16, 32, kernel_size=(15,), stride=(1,), padding=same)\n",
              "    (conv3t): Conv1d(32, 64, kernel_size=(5,), stride=(1,), padding=same)\n",
              "  )\n",
              "  (pretrain): Head_NN(\n",
              "    (layer): Sequential(\n",
              "      (0): Dropout(p=0.5, inplace=False)\n",
              "      (1): Linear(in_features=128000, out_features=5, bias=True)\n",
              "    )\n",
              "    (softmax): Softmax(dim=None)\n",
              "    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "model = torch.load('/content/Spectral__10s_ep2_.pt')\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2OEbge-bt3y"
      },
      "outputs": [],
      "source": [
        "loss_test = 0\n",
        "acc_test = 0\n",
        "for batch_idx, batch in enumerate(testLoader):\n",
        "  loss_batch, acc_batch = criterion.forward(batch, model, sfreq, train = False)\n",
        "  loss_test += loss_batch.item()\n",
        "  acc_test += acc_batch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYCSS-NjshUi",
        "outputId": "2b50586b-3bdc-453b-e1e1-0de412b3f014"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 1.7048326134681702\n",
            "acc: 0.19999999999999982\n"
          ]
        }
      ],
      "source": [
        "print('loss:',loss_test/len(testLoader))\n",
        "print('acc:',acc_test/len(testLoader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-P2ev1ebshZi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G25-VgpOshcm"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}