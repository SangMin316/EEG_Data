{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SangMin316/EEG_Data/blob/main/221027_sepectral_pathway_maxpool.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDWt74XAgpLK",
        "outputId": "ceaae8d6-4035-4a0d-dfc4-9fd7d389deb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mne in /usr/local/lib/python3.7/dist-packages (1.2.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from mne) (4.64.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from mne) (1.7.3)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mne) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from mne) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mne) (21.3)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.7/dist-packages (from mne) (1.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from mne) (2.11.3)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.5->mne) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.5->mne) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->mne) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->mne) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mne) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mne) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mne) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mne) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->mne) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install mne"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "l4YUYhC7E4Ck"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "import pickle\n",
        "import mne\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "class Sleepedf_dataset(Dataset):\n",
        "    def __init__(self, files, seq_len, SSL = bool):\n",
        "        self.files = files\n",
        "        self.sequence_length = seq_len\n",
        "        self.SSL = SSL\n",
        "        # sample을 split해줬을 때 몇개로 split되는지 누적해서 저장, i번째 data를 찾을 때 data_adress 각 값이 기준이 됨\n",
        "        data_adress = [0]\n",
        "        ad = 0\n",
        "        max_value = 0.\n",
        "        min_value = 0.\n",
        "\n",
        "        for i in range(len(self.files)):\n",
        "            sample = np.load(files[i])['x']\n",
        "            c,t = sample.shape\n",
        "            t = int(t/self.sequence_length) \n",
        "            ad += t\n",
        "            data_adress.append(ad)\n",
        "            temp_max = sample.max()\n",
        "            temp_min = sample.min()\n",
        "            max_value = np.max([max_value, temp_max])\n",
        "            min_value = np.min([min_value, temp_min])\n",
        "        \n",
        "        self.data_adress = data_adress\n",
        "        self.max_value = max_value\n",
        "        self.min_value = min_value\n",
        "\n",
        "    def preprocessing(self, data):\n",
        "        data_max = np.max(data,axis = 2, keepdims=True) # max value of each channels\n",
        "        data_min = np.min(data,axis = 2, keepdims=True) # shape = b,c\n",
        "        b,c,t = data.shape\n",
        "        \n",
        "        return data/data_max*np.ones((b,c,t)) - (data_max - data_min)*np.ones((b,c,t))/(self.max_value - self.min_value)\n",
        "\n",
        "\n",
        "    def split_data(self, data):\n",
        "        L = self.sequence_length\n",
        "        channels, length = data.shape\n",
        "        a = L*int(length/L)\n",
        "        \n",
        "        if length == a:\n",
        "            data = np.reshape(data,(int(length/L),channels,L))\n",
        "        \n",
        "        else:\n",
        "            data = data[:,:a]\n",
        "            data = np.reshape(data,(int(a/L),channels,L))\n",
        "        return data\n",
        "\n",
        "    def one_hot_encoding(self,y):\n",
        "        if y == 'Sleep stage W':\n",
        "          y = np.array([1,0,0,0,0])\n",
        "        elif y == 'Sleep stage 1':\n",
        "          y = np.array([0,1,0,0,0])\n",
        "        elif y == 'Sleep stage 2':\n",
        "          y = np.array([0,0,1,0,0])   \n",
        "        elif y == 'Sleep stage 3':\n",
        "          y = np.array([0,0,0,1,0])\n",
        "        elif y == 'Sleep stage R':\n",
        "          y = np.array([0,0,0,0,1])      \n",
        "        return y  \n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        for i in range(len(self.data_adress)):\n",
        "            if index < self.data_adress[i]:\n",
        "                break\n",
        "          \n",
        "        sample = np.load(self.files[i-1])  \n",
        "        y = self.one_hot_encoding(sample['y'])\n",
        "        sample = self.split_data(sample['x'])\n",
        "        sample = self.preprocessing(sample)\n",
        "\n",
        "        if self.SSL:\n",
        "          return sample[index - self.data_adress[i-1],:,:]\n",
        "        else:\n",
        "          return { 'x' : torch.tensor(sample[index - self.data_adress[i-1],:,:]), \n",
        "                   'y' : torch.tensor(y)\n",
        "                   }\n",
        "\n",
        "          \n",
        "          \n",
        "    def __len__(self):\n",
        "        return self.data_adress[-1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "x59y8HGhPIQB"
      },
      "outputs": [],
      "source": [
        "class MASS_dataset(Dataset):\n",
        "    def __init__(self, files, seq_len, SSL = bool):\n",
        "        self.files = files\n",
        "        self.sequence_length = seq_len\n",
        "        self.SSL = SSL\n",
        "        # self.freq = 1.28 # 256Hz / 1.28 = 200Hz\n",
        "        # sample을 split해줬을 때 몇개로 split되는지 누적해서 저장, i번째 data를 찾을 때 data_adress 각 값이 기준이 됨\n",
        "        data_adress = [0]\n",
        "        ad = 0\n",
        "        max_value = 0.\n",
        "        min_value = 0.\n",
        "\n",
        "        for i in range(len(self.files)):\n",
        "            sample = np.load(files[i])['x']\n",
        "            c,t = sample.shape\n",
        "            t = int(t/self.sequence_length) \n",
        "            ad += t\n",
        "            data_adress.append(ad)\n",
        "            temp_max = sample.max()\n",
        "            temp_min = sample.min()\n",
        "            max_value = np.max([max_value, temp_max])\n",
        "            min_value = np.min([min_value, temp_min])\n",
        "      \n",
        "        self.data_adress = data_adress\n",
        "        self.max_value = max_value\n",
        "        self.min_value = min_value\n",
        "\n",
        "    def preprocessing(self, data):\n",
        "        data_max = np.max(data,axis = 2, keepdims=True) # max value of each channels\n",
        "        data_min = np.min(data,axis = 2, keepdims=True) # shape = b,c\n",
        "        b,c,t = data.shape\n",
        "        \n",
        "        return data/data_max*np.ones((b,c,t)) - (data_max - data_min)*np.ones((b,c,t))/(self.max_value - self.min_value)\n",
        "\n",
        "\n",
        "    def split_data(self, data):\n",
        "        L = self.sequence_length\n",
        "        channels, length = data.shape\n",
        "        a = L*int(length/L)\n",
        "        \n",
        "        if length == a:\n",
        "            data = np.reshape(data,(int(length/L),channels,L))\n",
        "        \n",
        "        else:\n",
        "            data = data[:,:a]\n",
        "            data = np.reshape(data,(int(a/L),channels,L))\n",
        "        return data\n",
        "\n",
        "    def one_hot_encoding(self,y):\n",
        "        if y == 'Sleep stage W':\n",
        "          y = np.array([1,0,0,0,0])\n",
        "        elif y == 'Sleep stage 1':\n",
        "          y = np.array([0,1,0,0,0])\n",
        "        elif y == 'Sleep stage 2':\n",
        "          y = np.array([0,0,1,0,0])   \n",
        "        elif y == 'Sleep stage 3':\n",
        "          y = np.array([0,0,0,1,0])\n",
        "        elif y == 'Sleep stage R':\n",
        "          y = np.array([0,0,0,0,1])      \n",
        "        return y  \n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        for i in range(len(self.data_adress)):\n",
        "            if index < self.data_adress[i]:\n",
        "                break\n",
        "          \n",
        "        sample = np.load(self.files[i-1])  \n",
        "        y = self.one_hot_encoding(sample['y'])\n",
        "        sample = self.split_data(sample['x'])\n",
        "        sample = self.preprocessing(sample)\n",
        "\n",
        "        if self.SSL:\n",
        "          return sample[index - self.data_adress[i-1],:,:]\n",
        "        else:\n",
        "          return { 'x' : torch.tensor(sample[index - self.data_adress[i-1],:,:]), \n",
        "                   'y' : torch.tensor(y)\n",
        "                   }\n",
        "\n",
        "          \n",
        "    def __len__(self):\n",
        "        return self.data_adress[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dK-L4S1ZPOy8"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class concat_dataset():\n",
        "    def __init__(self, data_dic,seq_len):\n",
        "        self.data_dic = data_dic #data_dic : {'dataset1_name : [dataset1_adress],,,datasetN_name : [datasetN_adress]}\n",
        "        self.seq_len = seq_len\n",
        "    \n",
        "    def tr_val_te_split(self,data_list):\n",
        "        train, test = train_test_split(data_list, test_size=0.2)#, shuffle=True, random_state=34), #stratify=target\n",
        "        train, val = train_test_split(train, test_size= 0.25)#, shuffle=True, random_state=34)\n",
        "        del data_list\n",
        "        print('split done')\n",
        "        return train, val, test    \n",
        "    \n",
        "    def call(self):\n",
        "        # train_dataset = [] # extend로 빈 어레의 받으면 메모리가 터지는 문제 발생했음.\n",
        "        # val_dataset = []\n",
        "        # test_dataset = []\n",
        "    \n",
        "        for name, data_list in self.data_dic.items():\n",
        "            print(name)\n",
        "            tr, val, te = self.tr_val_te_split(data_list)\n",
        "            \n",
        "            if name =='Sleep_edf':\n",
        "                sleepedf_train_data = Sleepedf_dataset(tr,self.seq_len,SSL = True)\n",
        "                print('sleep train done')\n",
        "                sleepedf_val_data = Sleepedf_dataset(val,self.seq_len, SSL = True)\n",
        "                print('sleep val done')\n",
        "                sleepedf_test_data = Sleepedf_dataset(te,self.seq_len, SSL = True)\n",
        "                print('sleep test done')\n",
        "            \n",
        "            elif name == 'MASS':\n",
        "                MASS_train_data = Sleepedf_dataset(tr,self.seq_len, SSL = True)\n",
        "                print('MASS train done')\n",
        "                MASS_val_data = Sleepedf_dataset(val,self.seq_len, SSL = True)\n",
        "                print('MASS val done')\n",
        "                MASS_test_data = Sleepedf_dataset(te,self.seq_len, SSL = True)\n",
        "                print('MASS test done')\n",
        "        \n",
        "            # train_dataset.extend(train_data)\n",
        "            # val_dataset.extend(val_data)\n",
        "            # test_dataset.extend(test_data)\n",
        "            # print(train_data)\n",
        "\n",
        "        # del train_data,val_data, test_data\n",
        "    \n",
        "        train_dataset = torch.utils.data.ConcatDataset([sleepedf_train_data,MASS_train_data])\n",
        "        val_dataset = torch.utils.data.ConcatDataset([sleepedf_test_data,MASS_val_data])\n",
        "        test_dataset = torch.utils.data.ConcatDataset([sleepedf_val_data,MASS_test_data])\n",
        "    \n",
        "        return train_dataset, val_dataset, test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pk5UWrymWlfa",
        "outputId": "ed607779-f259-454e-996f-58cb26b1bb98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "153\n",
            "2650\n",
            "2830\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5480"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import glob\n",
        "SC_list = glob.glob('/content/drive/MyDrive/sleep_edfx/Preprocessed_EEG/SC/**')\n",
        "print(len(SC_list))\n",
        "sleepedf_list = []\n",
        "for i in range(2):\n",
        "  length = len(sleepedf_list)\n",
        "  sleepedf_list.extend(glob.glob(SC_list[i]+'/**'))\n",
        "  print(len(sleepedf_list) - length)\n",
        "len(sleepedf_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obBikyK6Wlhg",
        "outputId": "9a87eb76-5b6d-4183-e796-306962e9eb31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53\n",
            "1004\n",
            "1071\n",
            "937\n",
            "1041\n",
            "1079\n",
            "991\n",
            "877\n",
            "7000\n"
          ]
        }
      ],
      "source": [
        "SS1_list = glob.glob('/content/drive/MyDrive/EEG_data/MASS/SS1/Preprocessed_EEGedf/**')\n",
        "print(len(SS1_list))\n",
        "MASS_list = []\n",
        "for i in range(7,14):\n",
        "    length = len(MASS_list)\n",
        "    MASS_list.extend(glob.glob(SS1_list[i]+'/**'))\n",
        "    print(len(MASS_list) - length)\n",
        "print(len(MASS_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "eY3pJkIbWoFC"
      },
      "outputs": [],
      "source": [
        "data_dic = {'MASS' : MASS_list[:1000], 'Sleep_edf': sleepedf_list[:1000]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pb6mPckKWoHR",
        "outputId": "9fedf40d-9ecd-4339-9ac1-145b27dec3fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MASS\n",
            "split done\n",
            "MASS train done\n",
            "MASS val done\n",
            "MASS test done\n",
            "Sleep_edf\n",
            "split done\n",
            "sleep train done\n",
            "sleep val done\n",
            "sleep test done\n"
          ]
        }
      ],
      "source": [
        "train_dataset, val_dataset, test_dataset = concat_dataset(data_dic, seq_len = 200).call()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CcmiiI43YFCV"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "trainLoader = DataLoader(train_dataset, batch_size = 10 , shuffle= False)\n",
        "valLoader = DataLoader(val_dataset, batch_size = 10 , shuffle= False)\n",
        "testLoader = DataLoader(test_dataset, batch_size = 10 , shuffle= False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YWymlqfWs4T",
        "outputId": "767e8cfb-56f2-4edb-e4c0-9f4b29fc40cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch_idx: 0   torch.Size([10, 2, 200])\n",
            "time: 0.029386520385742188\n",
            "batch_idx: 1   torch.Size([10, 2, 200])\n",
            "time: 0.05707073211669922\n",
            "batch_idx: 2   torch.Size([10, 2, 200])\n",
            "time: 0.10046577453613281\n",
            "batch_idx: 3   torch.Size([10, 2, 200])\n",
            "time: 0.12891316413879395\n",
            "batch_idx: 4   torch.Size([10, 2, 200])\n",
            "time: 0.16936659812927246\n",
            "batch_idx: 5   torch.Size([10, 2, 200])\n",
            "time: 0.20062780380249023\n",
            "batch_idx: 6   torch.Size([10, 2, 200])\n",
            "time: 0.2271122932434082\n",
            "batch_idx: 7   torch.Size([10, 2, 200])\n",
            "time: 0.2703359127044678\n",
            "batch_idx: 8   torch.Size([10, 2, 200])\n",
            "time: 0.2999448776245117\n",
            "batch_idx: 9   torch.Size([10, 2, 200])\n",
            "time: 0.35770487785339355\n",
            "batch_idx: 10   torch.Size([10, 2, 200])\n",
            "time: 0.3987867832183838\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_T = time.time()\n",
        "for batch_idx, batch in enumerate(valLoader):\n",
        "  print('batch_idx:',batch_idx,' ',batch.shape)\n",
        "  end_T = time.time()\n",
        "  print('time:', end_T - start_T)\n",
        "  if batch_idx >= 10:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "834tX7V_uCyj",
        "outputId": "a77bd9e2-f634-4c6d-b20a-ede1ef033af7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: separableconv-torch in /usr/local/lib/python3.7/dist-packages (0.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from separableconv-torch) (1.21.6)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from separableconv-torch) (0.13.1+cu113)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from separableconv-torch) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->separableconv-torch) (4.1.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->separableconv-torch) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->separableconv-torch) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->separableconv-torch) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->separableconv-torch) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->separableconv-torch) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->separableconv-torch) (2.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install separableconv-torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "AISU52mNuvT0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from mne.filter import filter_data, notch_filter\n",
        "import matplotlib.pyplot as plt\n",
        "# import hypertools as hyp\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "\n",
        "class StoppedBandPredTaskLoss(torch.nn.modules.loss._Loss):\n",
        "    def __init__(self, bands, labels, device):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.BAND = bands\n",
        "        self.LABEL = labels\n",
        "\n",
        "    def forward(self, batch, encoder, sfreq, train):\n",
        "        batch_aug = []\n",
        "        batch_label = []\n",
        "        b,c,t = batch.shape\n",
        "        batch = np.reshape(batch,(c,b*t))        #Band has freqeuncy range, filter_data plays the role of Band Stop filter\n",
        "        \n",
        "        #each Labels are composed of one-hot vectors and are copied ( Bands size * Batch size )\n",
        "        for idx,band in enumerate(self.BAND):\n",
        "            lfreq, rfreq = band\n",
        "            data = filter_data(batch.numpy().astype(np.float64), sfreq=sfreq, l_freq=rfreq, h_freq=lfreq, verbose=False)\n",
        "            batch_aug.extend(data)\n",
        "            batch_label.extend((data.shape[0]*b) * [self.LABEL[idx]])\n",
        "\n",
        "        #[batch, augmentation, channel, time length] -> [batch*augmentation, channel, time length]\n",
        "        # b,a,l = np.array(batch_aug).shape\n",
        "        batch_aug = np.array(batch_aug)\n",
        " \n",
        "        batch_label = np.array(batch_label)\n",
        "        batch_aug = np.reshape(batch_aug,(5*c*b,1,t))\n",
        "        batch_label = torch.Tensor(batch_label).to(device)\n",
        "  \n",
        "        #Self-supervised Learning Loss is CrossEntropy\n",
        "        CrossEL = torch.nn.CrossEntropyLoss()\n",
        "        pred = encoder.forward(torch.Tensor(batch_aug).to(device))\n",
        "        loss = CrossEL(pred, batch_label)\n",
        "        _, y =  torch.max(batch_label, 1) \n",
        "        _, predicted = torch.max(pred, 1) \n",
        "        \n",
        "    \n",
        "        if train:\n",
        "            loss.backward(retain_graph=True)\n",
        "            \n",
        "        acc = (predicted == y).sum().item()\n",
        "        acc = acc/len(predicted) #acc/(batch*channels*5(augmented))\n",
        "        loss = loss\n",
        "      \n",
        "        del y\n",
        "        return loss, acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "aJVoejtCuxGB"
      },
      "outputs": [],
      "source": [
        "def weight_init_xavier_uniform(submodule):\n",
        "    # if isinstance(submodule, snn.SeparableConv1d):\n",
        "    #     torch.nn.init.xavier_uniform_(submodule.weight)\n",
        "\n",
        "    if isinstance(submodule, nn.Linear):\n",
        "        torch.nn.init.xavier_uniform_(submodule.weight)\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, fs, encode_info):\n",
        "        super(Encoder, self).__init__()\n",
        "        #spectral layer means spectral convolution\n",
        "        #self.bac_layer is consist of several SeparableConv2d, which plays the role of temporal separable convolution\n",
        "        #convolution layer are initiated by xavier_uniform initization\n",
        "        #Input are Normalized by self.bn(=torch.nn.BatchNorm2d)\n",
        "        #[batch, electrode, length] -> [batch, electrode, Feature]\n",
        "        self.fs = fs\n",
        "        self.elu = nn.ELU()\n",
        "        self.maxpool = nn.AdaptiveMaxPool1d(1)\n",
        "        self.bn = nn.BatchNorm1d(1)\n",
        "        self.activation = nn.LeakyReLU()\n",
        "\n",
        "        self.spectral_layer = nn.Conv1d(1, 10, int(self.fs/2), padding=\"same\")\n",
        "\n",
        "        # self.bac_layer = nn.Sequential()\n",
        "        # for i, arg in enumerate(encode_info):\n",
        "        #     input_dim, output_dim, kernel_size = arg\n",
        "        #     self.bac_layer.add_module(\"temporal_conv_\"+str(i),\n",
        "        #                           nn.Conv1d(input_dim, output_dim, kernel_size, padding = 'same'))\n",
        "        #     self.bac_layer.add_module(\"ELU\",nn.ELU()) \n",
        "        \n",
        "        self.conv1t = nn.Conv1d(10,16, 30, padding ='same')\n",
        "        self.conv2t = nn.Conv1d(16,32, 15, padding ='same')\n",
        "        self.conv3t = nn.Conv1d(32,64, 5, padding ='same')\n",
        "        \n",
        "        torch.nn.init.xavier_uniform_(self.spectral_layer.weight)\n",
        "        #self.bac_layer.apply(weight_init_xavier_uniform)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.activation(self.spectral_layer(x))\n",
        "        x = self.activation(self.conv1t(x))\n",
        "        x = self.activation(self.conv2t(x))\n",
        "        x = self.activation(self.conv3t(x))\n",
        "\n",
        "        return x\n",
        "\n",
        "#Linear layer for SSL classification\n",
        "class Head_NN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Head_NN, self).__init__()\n",
        "        self.length = length\n",
        "        \n",
        "        # self.layer = nn.Sequential(\n",
        "        #     nn.Dropout(0.5),\n",
        "        #     nn.Linear(64*length, 5)\n",
        "        # )\n",
        "        \n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(64, 5)\n",
        "        )\n",
        "        \n",
        "        self.softmax = torch.nn.Softmax()\n",
        "        # self.layer.apply(weight_init_xavier_uniform)\n",
        "        self.bn = nn.BatchNorm1d(64)\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.mean(x, axis = 2) # Global average pooling into temporal dimension\n",
        "        # x = self.flatten(x)\n",
        "        x = self.layer(x)\n",
        "        x = self.softmax(x)\n",
        "        return x\n",
        "\n",
        "class StoppedBandPathway(nn.Module):\n",
        "    def __init__(self, fs, Unsupervise, encode_info, bands):\n",
        "        super(StoppedBandPathway, self).__init__()\n",
        "        self.encoder = Encoder(fs, encode_info)\n",
        "        self.pretrain = Head_NN()\n",
        "        self.Unsupervise = Unsupervise\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.pretrain(x)\n",
        "        return x\n",
        "\n",
        "    def getRep(self, x):\n",
        "        x = self.encoder(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "E-HDYWxLaZiA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "# batch size\n",
        "batch_size = 250\n",
        "learning_rate = 0.001\n",
        "epochs = 20\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "#torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "#\"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TiQ9BH615R_",
        "outputId": "48d0425d-3b2e-4d19-9d5b-e00ee8e9731e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "SpnINn5J2AVM"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "trainLoader = DataLoader(train_dataset, batch_size = batch_size , shuffle= False)\n",
        "valLoader = DataLoader(val_dataset, batch_size = batch_size , shuffle= False)\n",
        "testLoader = DataLoader(test_dataset, batch_size = batch_size , shuffle= False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "gPM0DbXxuz9n"
      },
      "outputs": [],
      "source": [
        "BANDS = [(0.5,4), (4,8), (8,15), (15,30), (30,49.9)]\n",
        "LABEL = [[1,0,0,0,0],[0,1,0,0,0],[0,0,1,0,0],[0,0,0,1,0],[0,0,0,0,1]]\n",
        "\n",
        "encode_info = [(10, 16, 30),(16, 32, 15),(32, 64, 5)]\n",
        "sfreq = 200\n",
        "\n",
        "\n",
        "model = StoppedBandPathway(sfreq,True,encode_info,BANDS).to(device)\n",
        "#model = MSNN.feature_extractor3(sfreq).to(device)\n",
        "\n",
        "# Custom Tripletloss\n",
        "criterion = StoppedBandPredTaskLoss(BANDS, LABEL, device=device)\n",
        "\n",
        "\n",
        "# use Adam optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfGyOdRAbtyv",
        "outputId": "3fd7672b-386e-4a7d-833e-de9877b2e6dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:304: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  ../aten/src/ATen/native/Convolution.cpp:882.)\n",
            "  self.padding, self.dilation, self.groups)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:71: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        }
      ],
      "source": [
        "loss_tr = []\n",
        "loss_val = []\n",
        "acc_tr = []\n",
        "acc_val = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    loss_ep = 0  # add batch loss in epoch\n",
        "    acc_ep = 0\n",
        "    #concatdata.getTrain()\n",
        "    for batch_idx, batch in enumerate(trainLoader):\n",
        "        optimizer.zero_grad()\n",
        "        # print(batch.shape)\n",
        "        loss_batch, acc_batch = criterion.forward(batch, model, sfreq, train = True)\n",
        "        optimizer.step()\n",
        "        loss_ep += loss_batch.item()\n",
        "        acc_ep += acc_batch\n",
        "        # print('acc',acc_batch)\n",
        "        # print('loss:',loss_batch.item())\n",
        "    loss_tr.append((loss_ep)/len(trainLoader))\n",
        "    acc_tr.append((acc_ep)/len(trainLoader))\n",
        "\n",
        "    loss_ep_val = 0\n",
        "    acc_ep_val = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        loss_v = 0\n",
        "        acc_v = 0\n",
        "        #concatdata.getVal()\n",
        "        for batch_idx, batch in enumerate(valLoader):\n",
        "            loss_batch, acc_batch = criterion.forward(batch, model, sfreq, train = False)\n",
        "            loss_ep_val += loss_batch.item()\n",
        "            acc_ep_val += acc_batch\n",
        "    \n",
        "        loss_val.append((loss_ep_val)/len(valLoader))\n",
        "        acc_val.append((acc_ep_val)/len(valLoader))\n",
        "        print(\"epoch : \", epoch, \"  train loss : \", loss_tr[epoch], 'train acc : ', acc_tr[epoch], \"    val loss : \", loss_val[epoch], 'val acc : ', acc_val[epoch])  \n",
        "        torch.save(model,'Spectral__1s_ep' + str(epoch)+'_.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyYjI6wY4bew"
      },
      "source": [
        "result save and plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sULgDLvm2xHe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "col = ['loss_tr','loss_val','acc_tr','acc_val']\n",
        "data = np.array([loss_tr,\n",
        "                 loss_val,\n",
        "                 acc_tr,\n",
        "                 acc_val])\n",
        "print(data.shape)\n",
        "data = np.transpose(data)\n",
        "df = pd.DataFrame(data = data, columns= col)\n",
        "df.to_excel('s_Sleepedf+MASS_1s.xlsx', index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqo5atQngb6K"
      },
      "outputs": [],
      "source": [
        "# plt.figure(figsize =(15, 10))\n",
        "\n",
        "plt.plot(range(epochs), loss_tr, color='red')\n",
        "plt.plot(range(epochs), loss_val, color='blue')\n",
        "plt.title('Model loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "plt.savefig('s_Sleepedf+MASS_loss_1s',bbox_inches = 'tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qR7XCy2hPq6"
      },
      "outputs": [],
      "source": [
        "# plt.figure(figsize =(15, 10))\n",
        "plt.plot(range(epochs), acc_tr, color='red')\n",
        "plt.plot(range(epochs), acc_val, color='blue')\n",
        "plt.title('Model accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "plt.savefig('s_Sleepedf+MASS_accuracy_5s',bbox_inches = 'tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaNXMjTxw00n"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2HeGrHBwziU"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache() # GPU 캐시 데이터 삭제"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKq8oqGJ9vrw"
      },
      "outputs": [],
      "source": [
        "model = torch.load('/content/Spectral__5s_ep19_.pt')\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2OEbge-bt3y"
      },
      "outputs": [],
      "source": [
        "loss_test = 0\n",
        "acc_test = 0\n",
        "for batch_idx, batch in enumerate(testLoader):\n",
        "  loss_batch, acc_batch = criterion.forward(batch, model, sfreq, train = False)\n",
        "  loss_test += loss_batch.item()\n",
        "  acc_test += acc_batch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYCSS-NjshUi"
      },
      "outputs": [],
      "source": [
        "print('loss:',loss_test/len(testLoader))\n",
        "print('acc:',acc_test/len(testLoader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-P2ev1ebshZi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "G25-VgpOshcm"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "mount_file_id": "1aGUqliDn9TRbxi4q2fN3hwC9HQPNyKdI",
      "authorship_tag": "ABX9TyP4YsSFEhirT/42gsPtxVjw",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}